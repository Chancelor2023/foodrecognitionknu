{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chancelor2023/foodrecognitionknu/blob/main/Japanese_food_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBomtioOHPVY"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy kaggle.json to /root/.kaggle/ folder so that kaggle cli can access it.\n",
        "!mkdir /.kaggle\n",
        "!mv kaggle.json /.kaggle\n",
        "!mv /.kaggle /root/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d rkuo2000/uecfood256"
      ],
      "metadata": {
        "id": "LjQtbMlpHY-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"uecfood256.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"food-256\")"
      ],
      "metadata": {
        "id": "LnMv1l1aHhaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "6oZFb6QRHyoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from shutil import copy2\n",
        "from PIL import Image\n",
        "\n",
        "# 1. Charger les catégories depuis category.txt\n",
        "category_file = \"food-256/UECFOOD256/category.txt\"\n",
        "with open(category_file, 'r', encoding='utf-8') as f:\n",
        "    classes = [line.strip().split()[1] for line in f.readlines()[1:]]  # Ignorer la première ligne\n",
        "\n",
        "# 2. Définir les ratios\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.2\n",
        "TEST_RATIO = 0.1\n",
        "\n",
        "# 3. Créer la structure des dossiers\n",
        "base_path = \"food-256\"\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "for split in splits:\n",
        "    os.makedirs(os.path.join(base_path, split, \"images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_path, split, \"labels\"), exist_ok=True)\n",
        "\n",
        "# 4. Parcourir les dossiers de catégories\n",
        "uec_path = os.path.join(base_path, \"UECFOOD256\")\n",
        "for category_dir in os.listdir(uec_path):\n",
        "    category_path = os.path.join(uec_path, category_dir)\n",
        "    if not os.path.isdir(category_path) or not category_dir.isdigit():\n",
        "        continue\n",
        "\n",
        "    bb_info_file = os.path.join(category_path, \"bb_info.txt\")\n",
        "    if not os.path.exists(bb_info_file):\n",
        "        continue\n",
        "\n",
        "    # Charger les images\n",
        "    images = [img for img in os.listdir(category_path) if img.endswith(\".jpg\")]\n",
        "    random.shuffle(images)  # Mélanger les images\n",
        "\n",
        "    # Répartir les images\n",
        "    split_train = int(len(images) * TRAIN_RATIO)\n",
        "    split_val = int(len(images) * (TRAIN_RATIO + VAL_RATIO))\n",
        "\n",
        "    train_images = images[:split_train]\n",
        "    val_images = images[split_train:split_val]\n",
        "    test_images = images[split_val:]\n",
        "\n",
        "    # Parcourir chaque image\n",
        "    for image_name in images:\n",
        "        # Définir le chemin source et destination\n",
        "        image_path = os.path.join(category_path, image_name)\n",
        "        split = (\n",
        "            \"train\" if image_name in train_images else\n",
        "            \"val\" if image_name in val_images else\n",
        "            \"test\"\n",
        "        )\n",
        "        dest_image_dir = os.path.join(base_path, split, \"images\")\n",
        "        dest_label_dir = os.path.join(base_path, split, \"labels\")\n",
        "        dest_image_path = os.path.join(dest_image_dir, image_name)\n",
        "        dest_label_path = os.path.join(dest_label_dir, image_name.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "        # Charger les dimensions de l'image\n",
        "        with Image.open(image_path) as img:\n",
        "            image_width, image_height = img.size\n",
        "\n",
        "        # Extraire et convertir les annotations\n",
        "        with open(bb_info_file, 'r') as f_in, open(dest_label_path, 'w') as f_out:\n",
        "            for line in f_in:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 5 or parts[0] != image_name[:-4]:\n",
        "                    continue\n",
        "\n",
        "                x1, y1, x2, y2 = map(int, parts[1:5])\n",
        "                class_id = int(category_dir) - 1  # YOLO class IDs commencent à 0\n",
        "                x_center = (x1 + x2) / (2 * image_width)\n",
        "                y_center = (y1 + y2) / (2 * image_height)\n",
        "                width = (x2 - x1) / image_width\n",
        "                height = (y2 - y1) / image_height\n",
        "\n",
        "                # Écrire les annotations YOLO\n",
        "                f_out.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "\n",
        "        # Copier l'image dans le dossier correspondant\n",
        "        copy2(image_path, dest_image_path)\n",
        "\n",
        "print(\"Conversion terminée. Les données sont organisées.\")\n"
      ],
      "metadata": {
        "id": "NMSGwnKVID-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Chemins des dossiers d'images\n",
        "base_path = \"food-256\"\n",
        "train_path = os.path.join(base_path, \"train\", \"images\")\n",
        "val_path = os.path.join(base_path, \"val\", \"images\")\n",
        "test_path = os.path.join(base_path, \"test\", \"images\")\n",
        "\n",
        "# Nombre de classes\n",
        "nc = 256  # 256 classes dans votre dataset\n",
        "\n",
        "# Charger les noms des classes depuis category.txt\n",
        "category_file = \"food-256/UECFOOD256/category.txt\"\n",
        "with open(category_file, 'r', encoding='utf-8') as f:\n",
        "    classes = [line.strip().split()[1] for line in f.readlines()[1:]]  # Ignorer la première ligne (header)\n",
        "\n",
        "# Créer le fichier data.yaml\n",
        "yaml_content = f\"\"\"\n",
        "train: {os.path.abspath(train_path)}\n",
        "val: {os.path.abspath(val_path)}\n",
        "test: {os.path.abspath(test_path)}  # Retirer cette ligne si vous n'avez pas de test\n",
        "\n",
        "nc: {nc}\n",
        "\n",
        "names:\n",
        "\"\"\"\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    yaml_content += f\"  {i}: '{class_name}'\\n\"\n",
        "\n",
        "# Écrire le fichier data.yaml\n",
        "with open(os.path.join(base_path, \"data.yaml\"), 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"Le fichier data.yaml a été généré avec succès.\")\n"
      ],
      "metadata": {
        "id": "-ixzaA47gawO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Dossier original et dossier réduit\n",
        "original_dataset = \"/content/food-256\"\n",
        "reduced_dataset = \"/content/food-256-reduced\"\n",
        "\n",
        "# Créer la structure de dossiers pour le dataset réduit\n",
        "os.makedirs(reduced_dataset, exist_ok=True)\n",
        "os.makedirs(os.path.join(reduced_dataset, \"train/images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(reduced_dataset, \"train/labels\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(reduced_dataset, \"val/images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(reduced_dataset, \"val/labels\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(reduced_dataset, \"test/images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(reduced_dataset, \"test/labels\"), exist_ok=True)\n",
        "\n",
        "# Proportion de réduction (ici, 25% des images)\n",
        "reduction_ratio = 0.25\n",
        "\n",
        "# Parcourir les sous-dossiers train, val, test\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    images_dir = os.path.join(original_dataset, split, \"images\")\n",
        "    labels_dir = os.path.join(original_dataset, split, \"labels\")\n",
        "\n",
        "    reduced_images_dir = os.path.join(reduced_dataset, split, \"images\")\n",
        "    reduced_labels_dir = os.path.join(reduced_dataset, split, \"labels\")\n",
        "\n",
        "    # Lister toutes les images\n",
        "    images = os.listdir(images_dir)\n",
        "    num_images = len(images)\n",
        "\n",
        "    # Sélectionner aléatoirement 25% des images\n",
        "    selected_images = random.sample(images, int(num_images * reduction_ratio))\n",
        "\n",
        "    # Copier les images et leurs annotations\n",
        "    for image in selected_images:\n",
        "        image_path = os.path.join(images_dir, image)\n",
        "        label_path = os.path.join(labels_dir, image.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "        shutil.copy(image_path, os.path.join(reduced_images_dir, image))\n",
        "        shutil.copy(label_path, os.path.join(reduced_labels_dir, image.replace(\".jpg\", \".txt\")))\n",
        "\n",
        "print(f\"Dataset réduit créé avec succès dans {reduced_dataset}\")\n"
      ],
      "metadata": {
        "id": "OlGlUCKCKfAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Chemins des dossiers d'images\n",
        "base_path = \"food-256-reduced\"\n",
        "train_path = os.path.join(base_path, \"train\", \"images\")\n",
        "val_path = os.path.join(base_path, \"val\", \"images\")\n",
        "test_path = os.path.join(base_path, \"test\", \"images\")\n",
        "\n",
        "# Nombre de classes\n",
        "nc = 256  # 256 classes dans votre dataset\n",
        "\n",
        "# Charger les noms des classes depuis category.txt\n",
        "category_file = \"food-256/UECFOOD256/category.txt\"\n",
        "with open(category_file, 'r', encoding='utf-8') as f:\n",
        "    classes = [line.strip().split()[1] for line in f.readlines()[1:]]  # Ignorer la première ligne (header)\n",
        "\n",
        "# Créer le fichier data.yaml\n",
        "yaml_content = f\"\"\"\n",
        "train: {os.path.abspath(train_path)}\n",
        "val: {os.path.abspath(val_path)}\n",
        "test: {os.path.abspath(test_path)}  # Retirer cette ligne si vous n'avez pas de test\n",
        "\n",
        "nc: {nc}\n",
        "\n",
        "names:\n",
        "\"\"\"\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    yaml_content += f\"  {i}: '{class_name}'\\n\"\n",
        "\n",
        "# Écrire le fichier data.yaml\n",
        "with open(os.path.join(base_path, \"data.yaml\"), 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"Le fichier data.yaml a été généré avec succès.\")\n"
      ],
      "metadata": {
        "id": "RrpqJdGUMt1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py --img 640 --batch 16 --epochs 50 --data /content/food-256-reduced/data.yaml --weights yolov5s.pt\n"
      ],
      "metadata": {
        "id": "vDj_Q5QNeLG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python val.py --weights runs/train/exp/weights/best.pt --data data.yaml\n"
      ],
      "metadata": {
        "id": "NKTpds2JLWZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.5 --source chemin/vers/image.jpg\n"
      ],
      "metadata": {
        "id": "0gAQdzUMdNav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the folder you want to delete\n",
        "folder_path = \"/content/reduced-food-256\"\n",
        "\n",
        "# Remove the folder and all its contents\n",
        "shutil.rmtree(folder_path)\n",
        "print(f\"Folder {folder_path} has been deleted.\")\n"
      ],
      "metadata": {
        "id": "sSafVBf1JOlU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}